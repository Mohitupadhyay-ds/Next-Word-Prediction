Both the projects have been made using different tools in order to show variations. 

These projects clearly highlight the power of machine learning models.

The first project is made using NLTK which stands for **Natural Language ToolKit**. 

**NLTK** is one of the largest Python libraries for performing various Natural Language Processing tasks. 

From rudimentary tasks such as text pre-processing to tasks like vectorized representation of text – NLTK’s API has covered everything.
For more info. on NLTK you can refer to this link- https://www.geeksforgeeks.org/introduction-to-nltk-tokenization-stemming-lemmatization-pos-tagging/

The second project is made using transformers from **Hugging face**. Hugging Face Transformers is an open-source framework for deep learning. It provides APIs and tools to download state-of-the-art pre-trained models for natural language processing (NLP) tasks such as translation, named entity recognition, and text classification1.
You can refer to this link for further info.- https://huggingface.co/docs/transformers/index

In addition to that i have also build my own model from stratch by installing transformers as **!pip install transformers torch**.
I have also made use of "gpt2" model and "GPT2Tokenizer". 

